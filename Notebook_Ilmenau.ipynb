{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Esay Going Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Juypter Notebook wurde für den Vortrag *Textklassifikation mit Machine Learning* im Rahmen [DGPuK-Methoden-Tagung 2018 in Ilmenau](https://www.tu-ilmenau.de/en/computational-communication-science/dgpuk-methodentagung-2018/) erstellt und enthält ergänzenden Quellcode in der Programmiersprache Python (Python 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhalt\n",
    "\n",
    "* [Daten einlesen](#first-bullet)\n",
    "* [Modell auswählen](#second-bullet)\n",
    "* [Daten vorbereiten und aufteilen](#third-bullet)\n",
    "* [Modell trainieren](#4-bullet)\n",
    "* [Modell testen](#5-bullet)\n",
    "* [Modell evaluieren](#6-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen <a name=\"first-bullet\"></a>\n",
    "\n",
    "Mit Hilfe der Bibliothek **Pandas** können Daten aus einem .csv-File einlesen werden. Alternativ kann natürlich auch eine andere Bibliothek oder ein anderes Dateiformat gewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Pandas-Bibliothek aufrufen (zukünftig unter dem Kürzel pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"beispielposts.csv\") #.csv-File aus einem lokale Speicherort einlesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(file, sep=';', encoding=\"utf-8\") #File als pandas-DataFrame im Objekt df speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Klasse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Grund ist der hohe Ausl?nderanteil. Die Ta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bis zu -24 Grad!!!! ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entsprechende Schritte w?rden in den kommenden...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Hygiene-Center haben Toiletten, Duschen, W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F?r die tollste Frau der Welt! &lt;3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mehr Platz f?r dich! :-*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Sie sagen, sch?rfere Waffengesetze verringern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ihr esst gerne Tiefk?hlpizza? Dann k?nnte es s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auf jeden Fall ges?ndere Besch?ftigung als Zoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sonntagabend gemeinsam auf dem Sofa. ?? (via L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ein irakisches Gericht hat die Deutsche aus au...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Darauf muss man erstmal kommen ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nein, ihr seht nicht doppelt ... ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So sieht man Klitschko selten! &lt;3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Was ist das sch?nste Kompliment f?r dich? ?? (...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Klasse\n",
       "0   Der Grund ist der hohe Ausl?nderanteil. Die Ta...       1\n",
       "1                               Bis zu -24 Grad!!!! ?       1\n",
       "2   Entsprechende Schritte w?rden in den kommenden...       1\n",
       "3   Die Hygiene-Center haben Toiletten, Duschen, W...       1\n",
       "4                   F?r die tollste Frau der Welt! <3       1\n",
       "5                            Mehr Platz f?r dich! :-*       1\n",
       "6   \"Sie sagen, sch?rfere Waffengesetze verringern...       1\n",
       "7   Ihr esst gerne Tiefk?hlpizza? Dann k?nnte es s...       1\n",
       "8   Auf jeden Fall ges?ndere Besch?ftigung als Zoc...       1\n",
       "9   Sonntagabend gemeinsam auf dem Sofa. ?? (via L...       1\n",
       "10  Ein irakisches Gericht hat die Deutsche aus au...       1\n",
       "11                   Darauf muss man erstmal kommen ?       1\n",
       "12                 Nein, ihr seht nicht doppelt ... ?       1\n",
       "13                  So sieht man Klitschko selten! <3       1\n",
       "14  Was ist das sch?nste Kompliment f?r dich? ?? (...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15) #Zeigt die ersten 15 Fälle (Zeilen) des Data Frames, plus Header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #Anzahl der Fälle im Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell auswählen <a name=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Beispiel benutzen wir einen *Naive Bayes Classifier*, der sich als solide Baseline für Textklassifikationsprobleme auf Basis von Bag-of-Words eignet. Aus der Python-Bibliothek **scikit-learn (sklearn)** für ML\n",
    "importieren wir die Klasse `MultinomialNB` für multinominal verteilte Daten (Dokumentation [hier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #Lädt den Classifier MultinominalNB aus der sklearn-Bibliothek.\n",
    "\n",
    "\n",
    "MultinomialNB() #Default Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorbereiten und aufteilen <a name=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oft müssen die Daten noch mehr oder weniger aufwendig bearbeitet werden, bevor sie dem Modell zugeführt werden können. Für Textdaten kann diese Aufgabe besonders langwierig sein. Textverarbeitung kann z.B. mit den Bibliotheken **NLTK** oder **SpaCy** umgesetzt werden . Aber auch die ML-Bibliothek scikit-learn kann einige (einfache) Vorverarbeitung leisten. \n",
    "\n",
    "Die (vorverarbeiteten) Textdaten müssen noch in eine Bag-of-Words-Repräsenation überführt werden. Diese entspricht im Prinzip der (gewichteten) Verteilung der einzelnen Wörter in den Dokumenten wieder. Diese Aufgabe übernimmen die _Vectorizer_. Für eine absolute Häufigkeitsverteilung kann in sklearn der `CountVectorizer` verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importiert den CountVectorizer aus der sklearn-Bibliothek.\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die _Vectorizer_ in sklearn nehmen mehrere Argumente entgegen, die u.a. Informationen darüber enthalten, welche Wörter, Zeichen oder Wortgruppen berücksichtigt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Die folgenden Argumente können diesem Vectorizer übergeben werden.\n",
    "#In der Default-Einstellung werden beispielsweise keine Satzzeichen berückstichtigt.\n",
    "#Und Großbuchstaben werden zu Kleinbuchstaben.\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weißt dem Objekt vec den Vectorizer zu.\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machen wir einen kurzen Text anhand eines kleinen Textes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"Vielen Dank für die Blumen, vielen Dank, wie lieb von dir.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = vec.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 1, 1, 1, 2, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Der Feature-Vektor für den obigen Satz sieht nach der Vektorizierung wie folgt aus. \n",
    "# Nicht wundern, die Worter sind alphabetisch sortiert.\n",
    "\n",
    "test_vector.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blumen</th>\n",
       "      <th>dank</th>\n",
       "      <th>die</th>\n",
       "      <th>dir</th>\n",
       "      <th>für</th>\n",
       "      <th>lieb</th>\n",
       "      <th>vielen</th>\n",
       "      <th>von</th>\n",
       "      <th>wie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blumen  dank  die  dir  für  lieb  vielen  von  wie\n",
       "0       1     2    1    1    1     1       2    1    1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mit der Pandas-Bibliothek auch in schön:\n",
    "pd.DataFrame(test_vector.toarray(),columns=vec.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun müssen die Daten noch aufgeteilt werden. Im ML gibt es neben der folgenden Methode auch Verfahren, die den Datensatz mehrfach in Trainings- und Testsets aufteilen und stabiliere Schätzungen ermöglichen (-> Cross Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Text\"], #Als erstes wird X übergeben, hier df[\"Text\"].\n",
    "                                                    df[\"Klasse\"], #Als erstes Argument die Klasse y, hier df[\"Klasse\"].\n",
    "                                                    test_size=0.20, #20 % der Daten sollen Testdaten sein.\n",
    "                                                    random_state=4321) #Hier Random Number für die Zufallszuweisung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vectorizer verfügen über die Methoden `fit` und `transform` (oder `fit_transform`, wenn man beides auf einmal ausführen möchte). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vec.fit_transform(X_train.astype(\"U\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An den _Trainingsdaten_ wird der Vectorizer _gefittet_ und die Texte transformiert.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Im _Testdatensatz_ fittet der Vectorizer nicht(!) noch einmal an dem Vokabular, sondern _transformiert_ nur auf Basis der Features, die er aus dem Trainset kennt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = vec.transform(X_test.astype(\"U\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x27140 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 174441 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec \n",
    "#Die Bag-of-Words Matrix enthält 8000 Zeilen (Anzahl der Dokumente) x 27140 Spalten (Anzahl der Wörter im Gesamtcorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell trainieren <a name=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der `fit`-Methode, über die alle Classifier in sklearn verfügen, \"lernt\" das Modell, jedoch nur am Trainset, das aus `X_train_vec` und `y_train` besteht. \n",
    "\n",
    "Möchte man sich die Rechenzeit ausgeben lassen, geht das im Jupyter Notenbook über `%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vec, y_train) # %time model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell testen <a name=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell sagt nun die Klassen für die Testdaten voraus `X_test_vec`. Die Ergebnisse werden im Objekt `y_pred` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10] #Die ersten 10 vorhersagen sehen wie folgt aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell evaluieren <a name=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Modellevaluation werden die wahren Werte für Y aus dem Testset `y_test` mit den geschätzten Werten `y_pred` durch das Modell `model` abgeglichen. Alles was wir brauchen finden wir in sklearn bei *metrics*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>1562</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>366</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted 0  Predicted 1\n",
       "True 0         1562           32\n",
       "True 1          366           40"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    columns=['Predicted 0', 'Predicted 1'],\n",
    "    index=['True 0', 'True 1']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
